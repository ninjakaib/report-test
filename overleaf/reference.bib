@article{luo2024addition,
  title={Addition is All You Need for Energy-efficient Language Models},
  author={Luo, Hongyin and Sun, Wei},
  journal={arXiv preprint arXiv:2410.00907},
  year={2024}
}

@article{liu2024review,
  title={Review of neural network model acceleration techniques based on FPGA platforms},
  author={Liu, Fang and Li, Heyuan and Hu, Wei and He, Yanxiang},
  journal={Neurocomputing},
  pages={128511},
  year={2024},
  publisher={Elsevier}
}

@unpublished{b182023,
    title = {Enhancing Human Activity Recognition with Hardware Acceleration},
    author = {Cai, Louie and Lai, Jeffery and Gan, Lian and Dermanualian, Christian and Gupta, Rajesh},
    year = {2024},
    link = {https://louiecai.com/DSC-180B-Hardware-Acceleration/},
    note = {Note}
}

@article{de2023growing,
  title={The growing energy footprint of artificial intelligence},
  author={de Vries, Alex},
  journal={Joule},
  volume={7},
  number={10},
  pages={2191--2194},
  year={2023},
  publisher={Elsevier}
}

@misc{semianalysis2023,
  author = {SemiAnalysis},
  title = {The Inference Cost Of Search Disruption},
  year = {2023},
  url = {https://semianalysis.com/2023/02/09/the-inference-cost-of-search-disruption/},
  note = {Accessed: 2024-12-03}
}

@article{carbonfootprint2022,
  author={Patterson, David and Gonzalez, Joseph and Hölzle, Urs and Le, Quoc and Liang, Chen and Munguia, Lluis-Miquel and Rothchild, Daniel and So, David R. and Texier, Maud and Dean, Jeff},
  journal={Computer}, 
  title={The Carbon Footprint of Machine Learning Training Will Plateau, Then Shrink}, 
  year={2022},
  volume={55},
  number={7},
  pages={18-28},
  keywords={Training data;Machine learning;Carbon dioxide;Carbon footprint;Best practices;Emissions},
  doi={10.1109/MC.2022.3148714}
}

@inproceedings{clow2017pythonic,
  title={A pythonic approach for rapid hardware prototyping and instrumentation},
  author={Clow, John and Tzimpragos, Georgios and Dangwal, Deeksha and Guo, Sammy and McMahan, Joseph and Sherwood, Timothy},
  booktitle={2017 27th International Conference on Field Programmable Logic and Applications (FPL)},
  pages={1--7},
  year={2017},
  organization={IEEE}
}

@article{niknia2024asic,
  title={ASIC Design of Nanoscale Artificial Neural Networks for Inference/Training by Floating-Point Arithmetic},
  author={Niknia, Farzad and Wang, Ziheng and Liu, Shanshan and Reviriego, Pedro and Louri, Ahmed and Lombardi, Fabrizio},
  journal={IEEE Transactions on Nanotechnology},
  year={2024},
  publisher={IEEE}
}

@misc{5x5systolic,
    title={5×5 Systolic array architecture},
    author={ResearchGate},
    year={2024},
    url={https://www.researchgate.net/figure/55-Systolic-array-architecture_fig3_343586463}
}